{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAH0aZIeKun7"
      },
      "outputs": [],
      "source": [
        "!pip install numpy scipy pandas scikit-learn matplotlib seaborn torch hyperopt  copulae shapely tqdm online-conformal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNgpRdniZtur"
      },
      "outputs": [],
      "source": [
        "!pip install torchdiffeq\n",
        "!pip install epiweeks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HaX5LF-F9fd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYL_xZZdG1Uw"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "project_path = '/content/drive/MyDrive/cp-trajectory-master/'\n",
        "\n",
        "if not os.path.exists(project_path):\n",
        "    print(f\"ERROR: Path not found: {project_path}\")\n",
        "else:\n",
        "    sys.path.append(project_path)\n",
        "    print(f\"added {project_path} to system path.\")\n",
        "\n",
        "    print(\"Files found:\", os.listdir(project_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQzzTXF8ZFzh"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn.parameter import Parameter\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import scipy.integrate\n",
        "solve_ivp = scipy.integrate.solve_ivp\n",
        "from torchdiffeq import odeint\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import cp_ours\n",
        "import score_func\n",
        "import core.eval.eval_utils as eval\n",
        "from cp_ours import run_aci_simulation\n",
        "from score_func import score_function\n",
        "from cp_ours import collect_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZaUug5VZO5M"
      },
      "outputs": [],
      "source": [
        "class SIR(nn.Module):\n",
        "    \"\"\"\n",
        "    SEIR model for epidemiological modeling, commonly used for diseases like COVID-19.\n",
        "\n",
        "    Args:\n",
        "        N (int): Total population size.\n",
        "        Rt (float): Reproduction number.\n",
        "        beta_init (float): Initial value for the transmission rate parameter.\n",
        "        sigma_init (float): Initial value for the transition rate parameter.\n",
        "        reporting_rate (float): Fraction of cases reported, default is 0.025.\n",
        "    \"\"\"\n",
        "    def __init__(self, N, beta_init, gamma_init):\n",
        "        super().__init__()\n",
        "\n",
        "        self.N = N\n",
        "\n",
        "        EPS = -1e-12\n",
        "        self.beta = Parameter(torch.tensor(np.arctanh(2*beta_init  - 1), dtype=torch.float32))\n",
        "        self.gamma = Parameter(torch.tensor(np.arctanh(2 * gamma_init - 1 ), dtype=torch.float32))\n",
        "\n",
        "    def get_scaled_params(self, convert_cpu=False):\n",
        "        \"\"\"\n",
        "        Converts real-value parameters to scaled values in the range (0, 1).\n",
        "\n",
        "        Args:\n",
        "            convert_cpu (bool): If True, detach and convert parameters to CPU for visualization.\n",
        "\n",
        "        Returns:\n",
        "            dict: Scaled model parameters ('beta', 'sigma', 'gamma').\n",
        "        \"\"\"\n",
        "        params = {}\n",
        "\n",
        "        params['beta'] = 0.5 * (torch.tanh(self.beta) + 1)\n",
        "        params['gamma'] = 0.5 * (torch.tanh(self.gamma) + 1)\n",
        "        params['Rt'] = params['beta'] / (params['gamma'] + 1e-8)\n",
        "\n",
        "\n",
        "        if convert_cpu:\n",
        "            for k, v in params.items():\n",
        "                if torch.is_tensor(v):\n",
        "                    params[k] = v.detach().cpu().data.item()\n",
        "        return params\n",
        "\n",
        "\n",
        "    def forward(self, t, state):\n",
        "        \"\"\"\n",
        "        Computes the ODE derivatives for the SEIR model.\n",
        "\n",
        "        Args:\n",
        "            t (float): Current time.\n",
        "            state (Tensor): Current state values (S, E, I, R).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Derivatives of the state values.\n",
        "        \"\"\"\n",
        "        params = self.get_scaled_params()\n",
        "\n",
        "        S = state[0]\n",
        "        I = state[1]\n",
        "        R = state[2]\n",
        "\n",
        "        dS_dt = -params['beta'] * S * I / self.N\n",
        "\n",
        "        dI_dt = (params['beta'] * S * I / self.N) - (params['gamma'] * I)\n",
        "\n",
        "        dR_dt = params['gamma'] * I\n",
        "\n",
        "        return torch.stack([dS_dt, dI_dt, dR_dt], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF8UcNv7ZTS5"
      },
      "outputs": [],
      "source": [
        "class InitialConditions(nn.Module):\n",
        "    \"\"\"\n",
        "    Learnable initial conditions for the SEIR model states (S0, E0, I0, R0).\n",
        "\n",
        "    Args:\n",
        "        N (int): Total population size.\n",
        "        E0_init (float): Initial exposed population.\n",
        "        I0_init (float): Initial infectious population.\n",
        "        R0_init (float): Initial recovered population.\n",
        "    \"\"\"\n",
        "    def __init__(self, N, I0_init, R0_init):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        #self.E0 = Parameter(torch.tensor(E0_init, dtype=torch.float32))\n",
        "        self.I0 = Parameter(torch.tensor(I0_init, dtype=torch.float32))\n",
        "        self.R0 = Parameter(torch.tensor(R0_init, dtype=torch.float32))\n",
        "\n",
        "    def forward(self):\n",
        "        \"\"\"\n",
        "        Computes the initial susceptible population (S0) based on total population and initial conditions.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Initial state values [S0, E0, I0, R0].\n",
        "        \"\"\"\n",
        "        # TODO: Complete construction of initial conditions\n",
        "        S0 = self.N  - self.I0 - self.R0\n",
        "        return torch.stack([S0, self.I0, self.R0], 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EcWRuPuZXLK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model initialization\n",
        "beta = 0.33\n",
        "Rt = 1.19\n",
        "sigma = 0.48\n",
        "E0, I0, R0 = 600, 800, 1e4\n",
        "POP_SIZE = 372258 # population size\n",
        "\n",
        "\n",
        "# TODO: Instantiate the SEIR model and initial conditions\n",
        "init_conditions = InitialConditions(POP_SIZE, I0, R0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ8LkLCG1IOo"
      },
      "outputs": [],
      "source": [
        "# create data\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def simulate_sir(pop_size, beta, gamma, I0, R0, T):\n",
        "\n",
        "    model_phy = SIR(pop_size,  beta, gamma).cpu()\n",
        "    init_conditions = InitialConditions(pop_size,  I0, R0).cpu()\n",
        "\n",
        "    initial_conditions = init_conditions()\n",
        "    time_points = torch.linspace(0, T, T)\n",
        "\n",
        "    states = odeint(\n",
        "        model_phy,\n",
        "        initial_conditions,\n",
        "        time_points,\n",
        "        method=\"rk4\"\n",
        "    )\n",
        "\n",
        "    return states\n",
        "\n",
        "\n",
        "# build dataset\n",
        "def build_dataset(n=1000, T=200, pop_size=POP_SIZE):\n",
        "    X = torch.empty(n, T, 3, dtype=torch.float32)\n",
        "    Y = torch.empty(n, T, 3, dtype=torch.float32)\n",
        "\n",
        "    time_points = torch.linspace(0, T, T)\n",
        "    t_norm = (time_points / T).float()\n",
        "\n",
        "    for i in range(n):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Generated {i}/{n} trajectories\")\n",
        "\n",
        "\n",
        "        beta = torch.empty(1).uniform_(0.1, 0.7).item()\n",
        "        gamma = torch.empty(1).uniform_(0.05, 0.5).item()\n",
        "        I0, R0 =  800, 1e4\n",
        "\n",
        "        states = simulate_sir(pop_size, beta, gamma, I0, R0, T)\n",
        "        #normalizing\n",
        "        states = states.detach() / pop_size\n",
        "\n",
        "        params = torch.tensor([beta, gamma]).repeat(T, 1)\n",
        "\n",
        "        times = t_norm.view(T, 1)\n",
        "\n",
        "        input_vec = torch.cat([params, times], dim=1)\n",
        "\n",
        "        X[i] = input_vec\n",
        "        Y[i] = states\n",
        "\n",
        "    return X, Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9A7wWdADKc4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class SIRTransformer(nn.Module):\n",
        "    def __init__(self, hidden=128, nhead=4, num_layers=4, K=8, seq_len=200):\n",
        "        super().__init__()\n",
        "        self.K = K\n",
        "        self.hidden = hidden\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        input_dim = 2 + (2 * K) + 1\n",
        "\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=hidden*4,\n",
        "            batch_first=True,\n",
        "            dropout=0.1,\n",
        "            activation='gelu',\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.out_head = nn.Sequential(\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden, 3)\n",
        "        )\n",
        "\n",
        "    def time_features(self, t):\n",
        "        feats = []\n",
        "        for k in range(1, self.K + 1):\n",
        "            feats.append(torch.sin(2 * torch.pi * k * t))\n",
        "            feats.append(torch.cos(2 * torch.pi * k * t))\n",
        "        return torch.cat(feats, dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        total_points = x.size(0)\n",
        "\n",
        "        if total_points % self.seq_len == 0:\n",
        "            batch_size = total_points // self.seq_len\n",
        "            current_seq_len = self.seq_len\n",
        "        else:\n",
        "            batch_size = total_points\n",
        "            current_seq_len = 1\n",
        "\n",
        "        x_reshaped = x.view(batch_size, current_seq_len, 3)\n",
        "\n",
        "        params = x_reshaped[:, :, :2]\n",
        "        t = x_reshaped[:, :, 2:]\n",
        "        t_feats = self.time_features(t)\n",
        "        combined_feats = torch.cat([params, t,t_feats], dim=-1)\n",
        "\n",
        "        h = self.input_projection(combined_feats)\n",
        "\n",
        "        h = self.transformer(h)\n",
        "\n",
        "        out = self.out_head(h)\n",
        "\n",
        "        out = torch.softmax(out, dim=-1)\n",
        "\n",
        "        return out.reshape(total_points, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zofD6kov1Xmq"
      },
      "outputs": [],
      "source": [
        "def build_dataset(n=1000, T=200, pop_size=POP_SIZE, n_cal = 100, n_test = 100):\n",
        "    X = torch.empty(n, T, 3, dtype=torch.float32)\n",
        "    Y = torch.empty(n, T, 3, dtype=torch.float32)\n",
        "\n",
        "    #ncal and ntest sets of 10 trajcetories and 1 ground truth trajectory at index 0\n",
        "    X_cal = torch.empty(n_cal, 11, T, 3, dtype=torch.float32)\n",
        "    Y_cal = torch.empty(n_cal, 11, T, 3, dtype=torch.float32)\n",
        "\n",
        "    X_test = torch.empty(n_test, 11, T, 3, dtype=torch.float32)\n",
        "    Y_test = torch.empty(n_test, 11, T, 3, dtype=torch.float32)\n",
        "\n",
        "    time_points = torch.linspace(0, T, T)\n",
        "    t_norm = (time_points / T).float()\n",
        "    I0, R0 = 800, 1e4\n",
        "\n",
        "    for i in range(n_cal):\n",
        "      if i % 100 == 0:\n",
        "          print(f\"Generated {i}/{n_cal}  cal trajectories\")\n",
        "\n",
        "      #create range\n",
        "      base_beta  = np.random.uniform(0.6, 0.7)\n",
        "      base_gamma = np.random.uniform(0.4, 0.5)\n",
        "      #width of the calibration set\n",
        "      delta_b = 0.05\n",
        "      delta_g = 0.05\n",
        "\n",
        "      lower_b = max(0.6, base_beta  - delta_b)\n",
        "      upper_b = min(0.7, base_beta  + delta_b)\n",
        "\n",
        "      lower_g = max(0.4, base_gamma - delta_g)\n",
        "      upper_g = min(0.5, base_gamma + delta_g)\n",
        "      candidate_betas = []\n",
        "      candidate_gammas = []\n",
        "\n",
        "      for j in range(10):\n",
        "\n",
        "        gamma = np.random.uniform(lower_g, upper_g)\n",
        "        beta  = np.random.uniform(lower_b, upper_b)\n",
        "        candidate_betas.append(beta)\n",
        "        candidate_gammas.append(gamma)\n",
        "        states = simulate_sir(pop_size, beta, gamma, I0, R0, T)\n",
        "\n",
        "        states = states.detach() / pop_size\n",
        "        params = torch.tensor([beta, gamma]).repeat(T, 1)\n",
        "        times = t_norm.view(T, 1)\n",
        "        input_vec = torch.cat([params, times], dim=1)\n",
        "        X_cal[i, j+1] = input_vec\n",
        "        Y_cal[i, j+1] = states\n",
        "\n",
        "\n",
        "      #create GT\n",
        "      beta_true  = float(np.mean(candidate_betas))\n",
        "      gamma_true = float(np.mean(candidate_gammas))\n",
        "      states = simulate_sir(pop_size, beta_true, gamma_true, I0, R0, T)\n",
        "      states = states.detach() / pop_size\n",
        "      params = torch.tensor([beta_true, gamma_true]).repeat(T,1)\n",
        "      input_vec = torch.cat([params, times], dim=1)\n",
        "      X_cal[i,0] = input_vec\n",
        "      Y_cal[i,0] = states\n",
        "\n",
        "\n",
        "    for i in range(n_test):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Generated {i}/{n_test}  test trajectories\")\n",
        "        base_beta  = np.random.uniform(0.6, 0.7)\n",
        "        base_gamma = np.random.uniform(0.4, 0.5)\n",
        "\n",
        "        #smaller interval than calibration\n",
        "        delta_b = 0.05\n",
        "        delta_g = 0.05\n",
        "\n",
        "        lower_b = max(0.6, base_beta  - delta_b)\n",
        "        upper_b = min(0.7, base_beta  + delta_b)\n",
        "\n",
        "        lower_g = max(0.4, base_gamma - delta_g)\n",
        "        upper_g = min(0.5, base_gamma + delta_g)\n",
        "        candidate_betas = []\n",
        "        candidate_gammas = []\n",
        "\n",
        "        for j in range(10):\n",
        "\n",
        "          gamma = np.random.uniform(lower_g, upper_g)\n",
        "          beta  = np.random.uniform(lower_b, upper_b)\n",
        "          candidate_betas.append(beta)\n",
        "          candidate_gammas.append(gamma)\n",
        "          states = simulate_sir(pop_size, beta, gamma, I0, R0, T)\n",
        "\n",
        "          states = states.detach() / pop_size\n",
        "          params = torch.tensor([beta, gamma]).repeat(T, 1)\n",
        "          times = t_norm.view(T, 1)\n",
        "          input_vec = torch.cat([params, times], dim=1)\n",
        "          X_test[i, j+1] = input_vec\n",
        "          Y_test[i, j+1] = states\n",
        "        #create GT\n",
        "        beta_true  = float(np.mean(candidate_betas))\n",
        "        gamma_true = float(np.mean(candidate_gammas))\n",
        "\n",
        "        states = simulate_sir(pop_size, beta_true, gamma_true, I0, R0, T)\n",
        "        states = states.detach() / pop_size\n",
        "        params = torch.tensor([beta_true, gamma_true]).repeat(T,1)\n",
        "        input_vec = torch.cat([params, times], dim=1)\n",
        "        X_test[i,0] = input_vec\n",
        "        Y_test[i,0] = states\n",
        "\n",
        "\n",
        "    for i in range(n):\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Generated {i}/{n} trajectories\")\n",
        "\n",
        "        #outbreak vs decay\n",
        "        if i < n // 2:\n",
        "\n",
        "            gamma = np.random.uniform(0.1, 0.4)\n",
        "            beta  = np.random.uniform(gamma + 0.05, 0.7)\n",
        "        else:\n",
        "\n",
        "            gamma = np.random.uniform(0.2, 0.6)\n",
        "            beta  = np.random.uniform(0.1, gamma - 0.05)\n",
        "\n",
        "\n",
        "        states = simulate_sir(pop_size, beta, gamma, I0, R0, T)\n",
        "\n",
        "        states = states.detach() / pop_size\n",
        "\n",
        "        params = torch.tensor([beta, gamma]).repeat(T, 1)\n",
        "        times = t_norm.view(T, 1)\n",
        "        input_vec = torch.cat([params, times], dim=1)\n",
        "\n",
        "        X[i] = input_vec\n",
        "        Y[i] = states\n",
        "\n",
        "\n",
        "    indices = torch.randperm(n)\n",
        "    indices_cal = torch.randperm(n_cal)\n",
        "    indices_test = torch.randperm(n_test)\n",
        "    return X[indices], Y[indices], X_cal[indices_cal], Y_cal[indices_cal], X_test[indices_test ], Y_test[indices_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLPT7Lom4GTQ"
      },
      "outputs": [],
      "source": [
        "train_X, train_Y, X_cal, Y_cal, X_test, Y_test = build_dataset(\n",
        "    n=2000,\n",
        "    T=200,\n",
        "    n_cal=100,\n",
        "    n_test=10\n",
        ")\n",
        "\n",
        "print(f\"Dataset made:\")\n",
        "print(f\"  train_X: {train_X.shape}\")\n",
        "print(f\"  train_Y: {train_Y.shape}\")\n",
        "print(f\"  X_cal:   {X_cal.shape}\")\n",
        "print(f\"  Y_cal:   {Y_cal.shape}\")\n",
        "print(f\"  X_test:  {X_test.shape}\")\n",
        "print(f\"  Y_test:  {Y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZEOeEMgXvmE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "N = train_X.shape[0]\n",
        "train_N = int(0.8 * N)\n",
        "val_X, val_Y = train_X[train_N:], train_Y[train_N:]\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(train_X, train_Y),\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    drop_last=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15v4t_rFw1JI"
      },
      "outputs": [],
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"xb shape:\", xb.shape)\n",
        "    print(\"yb shape:\", yb.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97BbwHyQ2dR2"
      },
      "outputs": [],
      "source": [
        "class MSLELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        log_pred = torch.log(pred + 1e-6)\n",
        "\n",
        "        log_target = torch.log(target + 1e-6)\n",
        "\n",
        "        return torch.mean((log_pred - log_target)**2)\n",
        "\n",
        "\n",
        "sur = SIRTransformer(hidden=128, nhead=4,K=2, num_layers=4, seq_len=200 ).to(device)\n",
        "\n",
        "opt = torch.optim.Adam(sur.parameters(), lr=1e-4)\n",
        "loss_fn = MSLELoss()\n",
        "\n",
        "for epoch in range(200):\n",
        "    sur.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        xb_flat = xb.view(-1, 3)\n",
        "        yb_flat = yb.view(-1, 3)\n",
        "\n",
        "        pred = sur(xb_flat)\n",
        "\n",
        "        loss = loss_fn(pred, yb_flat)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    #validation\n",
        "    if epoch % 10 == 0:\n",
        "        sur.eval()\n",
        "        with torch.no_grad():\n",
        "            v_xb = val_X.to(device).view(-1, 3)\n",
        "            v_yb = val_Y.to(device).view(-1, 3)\n",
        "\n",
        "            val_pred = sur(v_xb)\n",
        "            val_loss = loss_fn(val_pred, v_yb).item()\n",
        "\n",
        "        print(f\"[Epoch {epoch:03d}] Train {total_loss/len(train_loader.dataset):.6f} | Val {val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdD-ZXGwKe1H"
      },
      "outputs": [],
      "source": [
        "class Transformer_DataGenerator:\n",
        "    def __init__(self, model, true_trajectory, candidate_params, pop_size, T_horizon, device='cuda'):\n",
        "        self.model = model\n",
        "        self.truth = true_trajectory\n",
        "        self.candidates = candidate_params\n",
        "        self.pop_size = pop_size\n",
        "        self.H = T_horizon\n",
        "        self.device = device\n",
        "        self.state_idx = 1\n",
        "        self.current_subset = \"Transformer_Ensemble\"\n",
        "\n",
        "    def get_reference_time(self, t_idx):\n",
        "        return t_idx\n",
        "\n",
        "    def get_trajectory_samples(self, t_idx, random=False):\n",
        "        H_eff = min(self.H, len(self.truth) - t_idx)\n",
        "\n",
        "        truth_seq = self.truth[t_idx:t_idx + H_eff, self.state_idx]\n",
        "        y_truth = truth_seq.cpu().numpy() * self.pop_size\n",
        "\n",
        "        N = len(self.candidates)\n",
        "        TRAIN_T = 200\n",
        "        t_start = t_idx / TRAIN_T\n",
        "        t_end = (t_idx + H_eff) / TRAIN_T\n",
        "        t_grid = torch.linspace(t_start, t_end, H_eff, device=self.device).view(-1, 1)\n",
        "\n",
        "        params_expanded = self.candidates.to(self.device).unsqueeze(1).repeat(1, H_eff, 1)\n",
        "        t_expanded = t_grid.unsqueeze(0).repeat(N, 1, 1)\n",
        "        model_input = torch.cat([params_expanded, t_expanded], dim=2)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.model.seq_len = H_eff\n",
        "            pred_flat = self.model(model_input.view(-1, 3))\n",
        "            pred_seq = pred_flat.view(N, H_eff, 3)\n",
        "            samples = pred_seq[:, :, self.state_idx].cpu().numpy() * self.pop_size\n",
        "\n",
        "\n",
        "        return y_truth, samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcFMhdpSMKMd"
      },
      "outputs": [],
      "source": [
        "#Runnning CP traj without calibration\n",
        "#params\n",
        "HORIZON = 10\n",
        "start_t = 20\n",
        "TRAIN_T = 200\n",
        "ALPHA = 0.1\n",
        "\n",
        "TRUTH_T = 200\n",
        "TOTAL_DAYS = 130\n",
        "\n",
        "\n",
        "\n",
        "#craft an ensemble of random params between a interval\n",
        "n_members = 20\n",
        "\n",
        "candidate_betas = 0.3 + (0.6 - 0.3) * torch.rand(n_members)\n",
        "candidate_gammas = 0.1 + (0.3 - 0.1) * torch.rand(n_members)\n",
        "\n",
        "ensemble_params = torch.stack([candidate_betas, candidate_gammas], dim=1)\n",
        "\n",
        "\n",
        "#pick a ground truth (choosing average for now)\n",
        "beta_true = torch.mean(candidate_betas).item()\n",
        "gamma_true = torch.mean(candidate_gammas).item()\n",
        "\n",
        "print(f\"\\nGround Truth: Beta={beta_true:3f}, Gamma={gamma_true:4f}\")\n",
        "\n",
        "# generate true trajectory\n",
        "truth_states = simulate_sir(\n",
        "    POP_SIZE,\n",
        "    beta_true,\n",
        "    gamma_true,\n",
        "    I0=800,\n",
        "    R0=1e4,\n",
        "    T=TRUTH_T\n",
        ")\n",
        "#normalize\n",
        "truth_traj = truth_states.detach() / POP_SIZE\n",
        "\n",
        "#initialize data gen\n",
        "data_gen = Transformer_DataGenerator(\n",
        "    model=sur,\n",
        "    true_trajectory=truth_traj,\n",
        "    candidate_params=ensemble_params,\n",
        "    pop_size=POP_SIZE,\n",
        "    T_horizon=HORIZON,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "\n",
        "#CP params\n",
        "cp_params = {\n",
        "    'gamma': 0.2,\n",
        "    'power': 0.5,\n",
        "    'B': 20,\n",
        "    'var_a': 0.5,\n",
        "    'score_window': 10,\n",
        "    'optim_arg': {'e_coeff_init': 0.01}\n",
        "}\n",
        "\n",
        "print(\"Starting CP-Traj\")\n",
        "#run cptraj\n",
        "timestamps, ground_truths, prediction_intervals = run_aci_simulation(\n",
        "    data_generator=data_gen,\n",
        "    score_func_args={'type': 'pcp', 'optional_args': {}},\n",
        "    S_max=POP_SIZE/4,\n",
        "    alpha=ALPHA,\n",
        "    T_obs=TOTAL_DAYS,\n",
        "    H=HORIZON,\n",
        "    N=n_members,\n",
        "    start_t=start_t,\n",
        "    params=cp_params,\n",
        "    method_opt='cpt',\n",
        "    plot=True,\n",
        ")\n",
        "\n",
        "print(\"CP-traj Complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7pHeQEUncQW"
      },
      "outputs": [],
      "source": [
        "#needed to copy over this function due to problems with importing cp Traj into colab\n",
        "def collect_scores(data_generator: Transformer_DataGenerator, score_func_args, T_obs=1000, H=15, N=20, start_t=10, twodim=False, subset_name=None):\n",
        "    \"\"\"\n",
        "    Collection of information for ACI simulation. Get Fs and S_max from additional subsets.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    score_func = score_function\n",
        "\n",
        "    # Score function parameters\n",
        "    score_function_type = score_func_args.get('type', 'abs-r')\n",
        "    score_function_optional_args = score_func_args.get('optional_args', {})\n",
        "\n",
        "    # Main simulation loop\n",
        "    record_list = []\n",
        "    for t in range(T_obs):\n",
        "        current_time = data_generator.get_reference_time(t)\n",
        "        y_truth, samp = data_generator.get_trajectory_samples(t, random=False)\n",
        "        samp = samp[:N]\n",
        "        for h in range(H):\n",
        "            record = {\n",
        "                'time': current_time,\n",
        "                'time_idx': t,\n",
        "                'horizon': h,\n",
        "                'score': score_func(y_truth, samp, h, type=score_function_type, optional_args=score_function_optional_args),\n",
        "                'ground_truth': y_truth[h],\n",
        "                'lat': np.nanmean(samp[:, h, 0]) if twodim else np.nanmean(samp[:, h]),\n",
        "                'lon': np.nanmean(samp[:, h, 1]) if twodim else 0.0,\n",
        "                'subset': subset_name,\n",
        "            }\n",
        "            record_list.append(record)\n",
        "    return record_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6TaKOdtu54M"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "cal_scores_list = []\n",
        "\n",
        "print(\"Collecting Calibration Scores\")\n",
        "score_func = score_function\n",
        "# Loop through calibration set samples\n",
        "for i in range(50):\n",
        "    # get GT amd inputs\n",
        "    truth_traj = Y_cal[i, 0]\n",
        "    ensemble_inputs = X_cal[i, 1:]\n",
        "    ensemble_params = ensemble_inputs[:, 0, :2]\n",
        "\n",
        "\n",
        "    # Initialize Generator\n",
        "    cal_gen = Transformer_DataGenerator(\n",
        "        model=sur,\n",
        "        true_trajectory=truth_traj.to(device),\n",
        "        candidate_params=ensemble_params.to(device),\n",
        "        pop_size=POP_SIZE,\n",
        "        T_horizon=10,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Collect scores for this sample\n",
        "    batch_scores = collect_scores(\n",
        "        data_generator=cal_gen,\n",
        "        score_func_args={'type': 'pcp', 'optional_args': {}},\n",
        "        T_obs=130,\n",
        "        H=10,\n",
        "        N=len(ensemble_params),\n",
        "        start_t=20,\n",
        "        subset_name='calibration'\n",
        "    )\n",
        "\n",
        "    cal_scores_list.extend(batch_scores)\n",
        "\n",
        "print(f\"Collected {len(cal_scores_list)} calibration scores.\")\n",
        "\n",
        "#save scores\n",
        "with open('calibration_scores.pkl', 'wb') as f:\n",
        "    pickle.dump(cal_scores_list, f)\n",
        "\n",
        "cp_config = {\n",
        "    'gamma': 0.1,\n",
        "    'score_window': 10,\n",
        "    'alpha': 0.1,\n",
        "    'power': 0.5\n",
        "}\n",
        "with open('cp_config.json', 'w') as f:\n",
        "    json.dump(cp_config, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw_YFkhnGaS5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
        "\n",
        "\n",
        "def evaluate_on__test(model, X_test, Y_test, pop_size,device=None, seq_len=200, make_plots=True):\n",
        "    model.eval()\n",
        "\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    n = len(X_test)\n",
        "\n",
        "    msle_list = []\n",
        "    mae_list = []\n",
        "    peaks = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n):\n",
        "            # GT trajectory\n",
        "            gt_input = X_test[i, 0].to(device)\n",
        "            gt_target = Y_test[i, 0, :, 1].cpu().numpy()\n",
        "            gt_target = gt_target * pop_size\n",
        "\n",
        "            peaks.append(gt_target.max())\n",
        "\n",
        "            # run model\n",
        "            orig_seq_len = getattr(model, \"seq_len\", None)\n",
        "            if orig_seq_len is not None:\n",
        "                model.seq_len = seq_len\n",
        "\n",
        "            pred = model(gt_input.view(-1, 3))\n",
        "            pred_curve = pred.view(seq_len, 3)[:, 1].cpu().numpy() * pop_size\n",
        "\n",
        "            if orig_seq_len is not None:\n",
        "                model.seq_len = orig_seq_len\n",
        "\n",
        "            gt_c = np.maximum(gt_target, 0)\n",
        "            pred_c = np.maximum(pred_curve, 0)\n",
        "\n",
        "            msle_list.append(mean_squared_log_error(gt_c, pred_c))\n",
        "            mae_list.append(mean_absolute_error(gt_c, pred_c))\n",
        "\n",
        "    msle_arr = np.asarray(msle_list)\n",
        "    mae_arr = np.asarray(mae_list)\n",
        "    peaks = np.asarray(peaks)\n",
        "\n",
        "    fig = None\n",
        "    if make_plots:\n",
        "        idx_sorted = np.argsort(peaks)\n",
        "        low_idx = idx_sorted[int(0.1 * len(peaks))]\n",
        "        mid_idx = idx_sorted[int(0.5 * len(peaks))]\n",
        "        high_idx = idx_sorted[int(0.9 * len(peaks))]\n",
        "\n",
        "        pick_idxs = [low_idx, mid_idx, high_idx]\n",
        "        labels = [\"Decay\", \"Moderate outbreak\", \"Severe outbreak\"]\n",
        "\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(16, 4), sharey=True)\n",
        "\n",
        "        for j, idx in enumerate(pick_idxs):\n",
        "            gt_target = Y_test[idx, 0, :, 1].cpu().numpy() * pop_size\n",
        "            gt_input = X_test[idx, 0].to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                orig_seq_len = getattr(model, \"seq_len\", None)\n",
        "                if orig_seq_len is not None:\n",
        "                    model.seq_len = seq_len\n",
        "\n",
        "                pred = model(gt_input.view(-1, 3))\n",
        "                pred_curve = pred.view(seq_len, 3)[:, 1].cpu().numpy() * pop_size\n",
        "\n",
        "                if orig_seq_len is not None:\n",
        "                    model.seq_len = orig_seq_len\n",
        "\n",
        "            beta = gt_input[0, 0].item()\n",
        "            gamma = gt_input[0, 1].item()\n",
        "            local_msle = msle_arr[idx]\n",
        "\n",
        "            ax = axes[j]\n",
        "            ax.plot(gt_target, label=\"ODE (truth)\", linewidth=2)\n",
        "            ax.plot(pred_curve, \"--\", label=\"surrogate\", linewidth=2)\n",
        "            ax.set_title(f\"{labels[j]}\\nβ={beta:.2f}, γ={gamma:.2f}\")\n",
        "            ax.set_xlabel(\"Time (days)\")\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(\"Infected individuals\")\n",
        "                ax.legend()\n",
        "\n",
        "            ax.grid(alpha=0.3)\n",
        "            ax.text(\n",
        "                0.5, 0.9,\n",
        "                f\"MSLE: {local_msle:.4f}\",\n",
        "                transform=ax.transAxes,\n",
        "                ha=\"center\",\n",
        "                bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"),\n",
        "                fontsize=9,\n",
        "            )\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    metrics = {\n",
        "        \"msle_mean\": float(msle_arr.mean()),\n",
        "        \"msle_std\": float(msle_arr.std()),\n",
        "        \"msle_median\": float(np.median(msle_arr)),\n",
        "        \"msle_p10\": float(np.percentile(msle_arr, 10)),\n",
        "        \"msle_p90\": float(np.percentile(msle_arr, 90)),\n",
        "        \"mae_mean\": float(mae_arr.mean()),\n",
        "        \"mae_std\": float(mae_arr.std()),\n",
        "        \"mae_median\": float(np.median(mae_arr)),\n",
        "        \"mae_p10\": float(np.percentile(mae_arr, 10)),\n",
        "        \"mae_p90\": float(np.percentile(mae_arr, 90)),\n",
        "        \"msle_all\": msle_arr,\n",
        "        \"mae_all\": mae_arr,\n",
        "    }\n",
        "\n",
        "\n",
        "    print(\n",
        "        f\"MSLE: mean={metrics['msle_mean']:.5f}, \"\n",
        "        f\"median={metrics['msle_median']:.5f}, \"\n",
        "        f\"[p10, p90]=[{metrics['msle_p10']:.5f}, {metrics['msle_p90']:.5f}]\"\n",
        "    )\n",
        "    print(\n",
        "        f\"MAE:  mean={metrics['mae_mean']:.1f}, \"\n",
        "        f\"median={metrics['mae_median']:.1f}, \"\n",
        "        f\"[p10, p90]=[{metrics['mae_p10']:.1f}, {metrics['mae_p90']:.1f}]\"\n",
        "    )\n",
        "\n",
        "    return metrics, fig\n",
        "\n",
        "\n",
        "# usage:\n",
        "metrics, fig = evaluate_on__test(sur, X_test, Y_test, POP_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3LPmR0iyoqE"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('calibration_scores.pkl', 'rb') as f:\n",
        "    loaded_scores = pickle.load(f)\n",
        "loaded_scores = pd.DataFrame(loaded_scores)\n",
        "\n",
        "coverage_by_test_idx = {}\n",
        "all_test_outputs = {}\n",
        "\n",
        "clean_scores = loaded_scores[loaded_scores['score'] < 100000].copy()\n",
        "clean_scores = clean_scores.drop(columns=['time_idx'])\n",
        "\n",
        "for i in range(10):\n",
        "  TEST_IDX = i\n",
        "  truth_traj = Y_test[TEST_IDX, 0]\n",
        "  ensemble_params = X_test[TEST_IDX, 1:, 0, :2]\n",
        "\n",
        "  test_gen = Transformer_DataGenerator(\n",
        "      model=sur,\n",
        "      true_trajectory=truth_traj.to(device),\n",
        "      candidate_params=ensemble_params.to(device),\n",
        "      pop_size=POP_SIZE,\n",
        "      T_horizon=10,\n",
        "      device=device\n",
        "  )\n",
        "\n",
        "  # 3. Define CP Parameters\n",
        "  cp_params = {\n",
        "      'gamma': 0.1,\n",
        "      'power': 0.5,\n",
        "      'B': 20,\n",
        "      'var_a': .5,\n",
        "      'score_window': 10,\n",
        "      'optim_arg': {'e_coeff_init': 0.01}\n",
        "  }\n",
        "\n",
        "  print(\"Running CP-Traj on Test\")\n",
        "  save_plot_path = \"/saveplot\"\n",
        "  os.makedirs(save_plot_path, exist_ok=True)\n",
        "\n",
        "  timestamps, ground_truths, prediction_intervals = run_aci_simulation(\n",
        "      data_generator=test_gen,\n",
        "      score_func_args={'type': 'pcp', 'optional_args': {}},\n",
        "      S_max=POP_SIZE ,\n",
        "      alpha=0.1,\n",
        "      T_obs=130,\n",
        "      H=10,\n",
        "      N=10,\n",
        "      start_t=20,\n",
        "      params=cp_params,\n",
        "      method_opt='cpt',\n",
        "      plot=True,\n",
        "      learned_scores=clean_scores,\n",
        "      save_path=save_plot_path\n",
        "  )\n",
        "\n",
        "  gt = np.array(ground_truths)\n",
        "  ivals = np.array(prediction_intervals)\n",
        "\n",
        "  lower_samples = ivals[..., 0]\n",
        "  upper_samples = ivals[..., 1]\n",
        "\n",
        "\n",
        "  lower = lower_samples.min(axis=2)\n",
        "  upper = upper_samples.max(axis=2)\n",
        "\n",
        "  in_band = (gt >= lower) & (gt <= upper)\n",
        "\n",
        "  covered_timesteps = in_band.all(axis=-1)\n",
        "\n",
        "  coverage_fraction = covered_timesteps.mean()\n",
        "\n",
        "  print(f\"Coverage for TEST_IDX {TEST_IDX}: {coverage_fraction * 100}%\")\n",
        "\n",
        "  all_test_outputs[TEST_IDX] = {\n",
        "      \"timestamps\": timestamps,\n",
        "      \"ground_truths\": ground_truths,\n",
        "      \"prediction_intervals\": prediction_intervals,\n",
        "      \"cp_params\": cp_params,\n",
        "      \"coverage_fraction\": float(coverage_fraction),\n",
        "  }\n",
        "\n",
        "  coverage_by_test_idx[TEST_IDX] = float(coverage_fraction)\n",
        "\n",
        "  print(\"Simulation Complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6150069"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "plots_to_display = [\n",
        "    \"horizon_coverage_expand_boundaries.png\",\n",
        "    \"coverage_expand_boundaries.png\",\n",
        "    \"alphas_h0.png\"\n",
        "]\n",
        "\n",
        "for plot_filename in plots_to_display:\n",
        "    full_path = os.path.join(save_plot_path, plot_filename)\n",
        "    if os.path.exists(full_path):\n",
        "        print(f\"Displaying: {plot_filename}\")\n",
        "        display(Image(filename=full_path))\n",
        "    else:\n",
        "        print(f\"Plot file '{plot_filename}' not found at '{full_path}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTLMyA349dsm"
      },
      "outputs": [],
      "source": [
        "# debug to see how the confidence intervals are performing\n",
        "def check_interval_widths(day_idx, prediction_intervals, pop_size=372258):\n",
        "    step = 5\n",
        "\n",
        "    print(f\"Tube Widths at Day {day_idx} + {step} days ahead\")\n",
        "    for i in range(5):\n",
        "        lower = prediction_intervals[day_idx, step, i, 0]\n",
        "        upper = prediction_intervals[day_idx, step, i, 1]\n",
        "        width = upper - lower\n",
        "        print(f\"Member {i}: Width = {width:.0f} (Coverage: {lower:.0f} to {upper:.0f})\")\n",
        "\n",
        "\n",
        "check_interval_widths(90, prediction_intervals, POP_SIZE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}